<!DOCTYPE html>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Christoph Feichtenhofer</title>
  <link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
  <link href="css/style.css" rel="stylesheet">
  <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600|Arvo:700" rel="stylesheet" type="text/css" />
    <link href='http://fonts.googleapis.com/css?family=Roboto:400,300,500' rel='stylesheet' type='text/css'>

  <style type="text/css"></style>

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-58616069-1', 'auto');
  ga('send', 'pageview');

</script>

</head>

<body>
<div id="top" class="chart">


<div id="header" class="bg2"> 


<div id="top" class="chart">


  <div id="headerblob">
    <img src="./img/chris.jpg" class="img-circle imgme"  width="130px">
    <div id="headertext">
      <div id="htname" style="color:white">Christoph Feichtenhofer</div>
      <div id="htdesc" style="color:white">PhD Student, Graz University of Technology</div>
      <div id="htem" style="color:white">feichtenhofer _at_ tugraz.at</div>
      <div id="icons">
        <div class="svgico">
          <a href="https://plus.google.com/117756895023424530482/posts"><img src="./img/80-google-plus.svg"></a>
        </div>
        <div class="svgico">
          <a href="https://github.com/feichtenhofer"><img src="./img/octocat.svg" width="56px"></a>
		</div>
        <div class="svgico">
          <a href="http://scholar.google.com/citations?user=UxuqG1EAAAAJ"><img src="./img/gscholar.svg" width="50px"></a>		  
        </div>
      </div>
    </div>
  </div>
</div>
</div>
<br><br>

<div class="container quote">
  <h3>Research Statement</h3>

  <blockquote>
<p class="text-left">My research interests are in the fields of computer vision and machine learning, with a focus on learning effective video representations for dynamic scene understanding. In particular, I plan to explore computational theories that represent spatiotemporal visual information, within a confluence of machine vision and learning. I aim to find efficient solutions for problems that are grounded in applications such as video search and retrieval. </p>

  </blockquote>
</div>

<div class="container">
  <h3>Education</h3>
  <div id="timeline">
    <div class="timelineitem">
      <div class="tdate">Since 2014</div>
      <div class="ttitle">Graz University of Technology: PhD Student</div>
      <div class="tdesc">Specialization on <span class="thigh">Learning Effective Spatiotemporal Representations for Recognition in Computer Vision </span></div>
    </div>
	<div class="timelineitem">
      <div class="tdate">2012 - 2013</div>
      <div class="ttitle">Graz University of Technology: Master's Degree </div>
      <div class="tdesc">Thesis: <span class="thigh">Dynamic Scene Recognition with Oriented Spacetime Energies</span></div>
    </div>
    <div class="timelineitem">
      <div class="tdate">03/2013 - 06/2013</div>
      <div class="ttitle">York University, Toronto, Canada: Visiting Researcher  </div>
	  <div class="tdesc"> Worked with Prof. Richard P. Wildes in the field of Dynamic Scene Recognition </div>
    </div>
    <div class="timelineitem">
      <div class="tdate">2008 - 2011
      </div>
      <div class="ttitle">Graz University of Technology: Bachelor's Degree </div>
      <div class="tdesc">Thesis: <span class="thigh">No-Reference Sharpness Metric based on Local Gradient Analysis</span></div>
    </div>
  </div>
</div>



<hr class="soft">

<div class="container">
  <h2>Publications</h2>
  <div id="pubs">

    <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
		  <video autoplay loop>
			  <source src="pubs/windmill_energies.mp4" type="video/mp4">
				Your browser does not support the video tag.  Download the video <a href=="img/windmill_energies.mp4">here</a>.
			</video>

          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Bags of Spacetime Energies for Dynamic Scene Recognition</div>
            <div class="pubd">This paper presents a unified bag of visual word (BoW) framework for dynamic scene recognition. The approach builds on primitive features that uniformly capture spatial and temporal orientation structure of the imagery (e.g., video), as extracted via application of a bank of spatiotemporally oriented filters. Various feature encoding techniques are investigated to abstract the primitives to an intermediate representation that is best suited to dynamic scene representation. Further, a novel approach to adaptive pooling of the encoded features is presented that captures spatial layout of the scene even while being robust to situations where camera motion and scene dynamics are confounded. The resulting overall approach has been evaluated on two standard, publically available dynamic scene datasets. The results show that in comparison to a representative set of alternatives, the proposed approach outperforms the previous state-of-the-art in classification accuracy by 10%.</div>
            <div class="puba">Christoph Feichtenhofer, Axel Pinz, Richard P. Wildes</div>
            <div class="pubv">in Proc. CVPR 2014 </div>
            <div class="publ">
              <ul>
                <li><a href="pubs/Feichtenhofer_Bags_of_Spacetime_2014_CVPR_paper.pdf">PDF</a></li>
			<li><a href="#" onClick="BoSESpotlight=window.open('pubs/BoSE_spotlight.mp4','BoSESpotlight','toolbar=no, location=no, directories=no,status=no, menubar=no,scrollbars=no, resizable=true'); return false;">Spotlight Video</a></li>
			
              </ul>
			  
            </div>
          </div>
        </div>
      </div>
    </div>
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="pubs/strf.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Spacetime Forests with Complementary
									Features for Dynamic Scene Recognition</div>
            <div class="pubd">This paper presents spacetime forests defined over complementary spatial and temporal
								features for recognition of naturally occurring dynamic scenes. The approach
								improves on the previous state-of-the-art in both classification and execution rates. A
								particular improvement is with increased robustness to camera motion, where previous
								approaches have experienced difficulty. There are three key novelties in the approach.
								First, a novel spacetime descriptor is employed that exploits the complementary nature
								of spatial and temporal information, as inspired by previous research on the role of orientation
								features in scene classification. Second, a forest-based classifier is used to learn
								a multi-class representation of the feature distributions. Third, the video is processed in
								temporal slices with scale matched preferentially to scene dynamics over camera motion.
								Slicing allows for temporal alignment to be handled as latent information in the classifier
								and for efficient, incremental processing. The integrated approach is evaluated empirically
								on two publically available datasets to document its outstanding performance.
			</div>
            <div class="puba">Christoph Feichtenhofer, Axel Pinz, Richard P. Wildes</div>
            <div class="pubv">in Proc. CVPR 2014 </div>
            <div class="publ">
              <ul>
                <li><a href="pubs/spacetime_forests_BMVC14.pdf">PDF</a></li>			
              </ul>
			  
            </div>
          </div>
        </div>
      </div>
	</div>  
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="pubs/rfid_vision_block_diagram.svg"><br><br>
			<img src="pubs/rfid_SP-ST.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Fusing RFID and Computer Vision for Probabilistic Tag Localization</div>
            <div class="pubd">The combination of RFID and computer vision
						systems is an effective approach to mitigate the limited tag
						localization capabilities of current RFID deployments. In this
						paper, we present a hybrid RFID and computer vision system
						for localization and tracking of RFID tags. The proposed system
						combines the information from the two complementary sensor
						modalities in a probabilistic manner and provides a high degree
						of ﬂexibility. In addition, we introduce a robust data association
						method which is crucial for the application in practical scenarios.
						To demonstrate the performance of the proposed system, we
						conduct a series of experiments in an article surveillance setup.
						This is a frequent application for RFID systems in retail where
						previous approaches solely based on RFID localization have
						difﬁculties due to false alarms triggered by stationary tags. Our
						evaluation shows that the fusion of RFID and computer vision
						provides robustness to false positive observations and allows for
						a reliable system operation.</div>
            <div class="puba">Michael Goller, Christoph Feichtenhofer, Axel Pinz</div>
            <div class="pubv">in Proc. IEEE RFID 2014 </div>
            <div class="publ">
              <ul>
                <li><a href="pubs/Goller_fusing_RFID_with_Vision_2014.pdf">PDF</a></li>			
              </ul>
			  
            </div>
          </div>
        </div>
      </div>
    </div>
	  <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <img src="pubs/stm_hom.jpg">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">Spatio-Temporal Good Features to Track</div>
            <div class="pubd">This paper presents two fundamental contributions that
								can be very useful for any autonomous system that requires
								point correspondences for visual odometry. First,
								the Spatio-Temporal Monitor (STM) is an efficient method
								to identify good features to track by monitoring their spatiotemporal
								(x-y-t) appearance without any assumptions about
								motion or geometry. The STM may be used with any spatial
								(x-y) descriptor, but it performs best when combined with
								our second contribution, the Histogram of Oriented Magnitudes
								(HOM) descriptor, which is based on spatially oriented
								multiscale filter magnitudes. To fulfil the real-time requirements
								of autonomous applications, the same descriptor
								can be used for both, track generation and monitoring,
								to identify low-quality feature tracks at virtually no additional
								computational cost. Our extensive experimental validation
								on a challenging public dataset demonstrates the
								excellent performance of STM and HOM, where we significantly
								outperform the well known “Good Features to
								Track” method and show that our proposed feature quality
								measure highly correlates with the accuracy in structure
								and motion estimation.
			</div>
            <div class="puba">Christoph Feichtenhofer, Axel Pinz</div>
            <div class="pubv">in Proc. CVAD, ICCV 2013 </div>
            <div class="publ">
              <ul>
                <li><a href="pubs/Feichtenhofer_Bags_of_Spacetime_2014_CVPR_paper.pdf">PDF</a></li>			
              </ul>
			  
            </div>
          </div>
        </div>
      </div>
	</div>  
	
	<div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
			<img src="pubs/sharpness/monarchblocks10pct.png">
          </div>
        </div>
        <div class="col-md-6">
          <div class="pub">
            <div class="pubt">A Perceptual Image Sharpness Metric Based on
								Local Edge Gradient Analysis</div>
            <div class="pubd">In this letter, a no-reference perceptual sharpness
						metric based on a statistical analysis of local edge gradients is
						presented. The method takes properties of the human visual
						system into account. Based on perceptual properties, a relation-
						ship between the extracted statistical features and the metric
						score is established to form a Perceptual Sharpness Index (PSI). A
						comparison with state-of-the-art metrics shows that the proposed
						method correlates highly with human perception and exhibits low
						computational complexity. In contrast to existing metrics, the PSI
						performs well for a wide range of blurriness and shows a high
						degree of invariance for different image contents.</div>
            <div class="puba">Christoph Feichtenhofer, Hannes Fassold, Peter Schallauer</div>
            <div class="pubv">in IEEE Signal Processing Letters 2013 </div>
            <div class="publ">
              <ul>
                <li><a href="pubs/Feichtenhofer_Image_Sharpness_Metric_IEEE_SPL_2013.pdf">PDF</a></li>			
              </ul>
			  
            </div>
          </div>
        </div>
      </div>
	
	
    </div>
  </div>
</div>



<hr class="soft">

<div class="container">
  <h2>Teaching</h2>
  <div class="ctr">
    <div class="pubt">Image and Video Understanding (together with Prof. Axel Pinz (winter 2014-2015)</div>
      <img src="./pubs/teaching/dynamic_scene_understanding.png" width="1000px">
    </a>
  </div>
  <h3>Lectures</h3>
  <div class="ctr">
    <div class="hht"><a href="pubs/teaching/IVU_Convolutional_Filtering_and_Thinking_in_Frequency.pdf">Convolutional Filtering and Thinking in Frequency </a> </div>
  </div>
  <div class="ctr">
    <div class="hht"><a href="pubs/teaching/IVU_Convolutional_Networks_and_Video_Representations.pdf">Convolutional Networks and Video Representations</a> </div>
  </div>
</div>

<hr class="soft">

<div id="sitefooter">

</div>


</body></html>